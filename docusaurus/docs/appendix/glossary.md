---
sidebar_position: 3
title: Glossary
---

# Glossary

This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics documentation.

## A

**Actuator**: A mechanical device that moves or controls a mechanism or system, typically converting electrical energy into mechanical motion.

**Artificial Intelligence (AI)**: The simulation of human intelligence processes by machines, especially computer systems, including learning, reasoning, and self-correction.

**Autonomous System**: A system that can operate independently without human intervention, making decisions based on its programming and sensor inputs.

## B

**Balance Control**: The process of maintaining the center of mass of a robot within its support polygon to prevent falling.

**Bipedal**: Having two feet; refers to robots that walk using two legs.

**Bipedal Locomotion**: The act of walking on two legs, a key capability for humanoid robots.

## C

**Center of Mass (CoM)**: The point in a body where the total mass is concentrated for the purpose of analyzing translational motion.

**Collision Detection**: The computational problem of detecting the intersection of two or more objects in virtual or physical space.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world.

**Control Theory**: An engineering and mathematics field that deals with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback.

**Cognitive Planning**: The process of creating a sequence of actions to achieve a goal using reasoning and understanding of the environment.

## D

**Deep Learning**: A subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns.

**Degrees of Freedom (DOF)**: The number of independent parameters that define the configuration or state of a mechanical system.

**Digital Twin**: A virtual representation of a physical system that can be used for simulation, testing, and validation.

**Dynamic Balance**: The ability to maintain balance while moving, as opposed to static balance which is balance while stationary.

## E

**Embodied Intelligence**: Intelligence that emerges from the interaction between an agent and its physical environment.

**End Effector**: The device at the end of a robotic arm designed to interact with the environment.

**Emergency Stop**: A safety mechanism that immediately halts robot operation in dangerous situations.

## F

**Forward Kinematics**: The use of joint parameters to compute the position and orientation of the end effector.

**Footstep Planning**: The process of determining where and when to place feet for stable bipedal locomotion.

**Force Control**: A control strategy that regulates the forces applied by a robot to its environment.

## G

**Gait**: The pattern of movement of the limbs of legged robots, particularly the rhythm of walking or running.

**Gazebo**: A 3D simulation environment for robotics that provides accurate physics simulation and rendering.

**Geometric Jacobian**: A matrix that relates the joint velocities to the end-effector velocity.

## H

**Human-Robot Interaction (HRI)**: The field of study focusing on the design, development, and evaluation of robots for human interaction.

**Humanoid Robot**: A robot with physical characteristics similar to humans, typically having a head, torso, two arms, and two legs.

## I

**Inertial Measurement Unit (IMU)**: An electronic device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body.

**Inverse Kinematics**: The mathematical process of calculating joint parameters from the desired end-effector position.

**Isaac ROS**: NVIDIA's collection of ROS 2 packages for perception, navigation, and manipulation using GPU acceleration.

**Isaac Sim**: NVIDIA's high-fidelity simulation environment built on the Omniverse platform.

## J

**Joint**: A connection between two or more links that allows relative motion between them.

**Joint Space**: The space defined by the joint angles of a robotic system.

## K

**Kinematics**: The branch of mechanics concerned with the motion of objects without reference to the forces that cause the motion.

**Kinesthetic Teaching**: A method of programming robots by physically guiding them through the desired motions.

## L

**Legged Locomotion**: The act of moving using legs, a key capability for robots operating in human environments.

**Large Language Model (LLM)**: A type of artificial intelligence model that can understand and generate human language based on training data.

**Lidar**: A remote sensing method that uses light in the form of a pulsed laser to measure distances.

**Locomotion**: The ability to move from one place to another.

## M

**Manipulation**: The skillful handling or controlling of objects, typically using robot arms and end effectors.

**Machine Learning (ML)**: A type of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed.

**Middleware**: Software that provides common services and capabilities to applications beyond what's offered by the operating system.

**Motor Controller**: A device that controls the operation of electric motors.

## N

**Navigation**: The process of planning and executing a path from one location to another.

**Natural Language Processing (NLP)**: A branch of AI that helps computers understand, interpret, and respond to human language.

**Neural Network**: A computing system inspired by the human brain that learns to perform tasks by considering examples.

**Node**: In ROS, a process that performs computation. Nodes are the fundamental building blocks of a ROS system.

## O

**Omniverse**: NVIDIA's simulation and collaboration platform for 3D design workflows.

**Operational Space**: The space in which motion is planned and controlled, typically Cartesian space.

**OpenAI**: An artificial intelligence research laboratory consisting of the for-profit OpenAI LP and the non-profit OpenAI Inc.

## P

**Perception**: The ability of a robot to sense and interpret its environment through various sensors.

**Physical AI**: Artificial intelligence systems that interact with and operate in the physical world through robotic platforms.

**Point Cloud**: A set of data points in space, typically representing the external surface of an object.

**Pose**: The position and orientation of an object in space.

**Proportional-Integral-Derivative (PID) Controller**: A control loop mechanism employing feedback used in industrial control systems.

## Q

**QoS (Quality of Service)**: In ROS 2, a set of policies that determine how messages are delivered between nodes.

## R

**Robot Operating System (ROS)**: A flexible framework for writing robot software that provides hardware abstraction, device drivers, libraries, visualizers, and more.

**ROS 2**: The second generation of the Robot Operating System with improved security, real-time support, and multi-robot capabilities.

**Rigid Body**: An object that maintains a constant distance between any two points within it.

**rclpy**: The Python client library for ROS 2.

**Real-time System**: A system that must respond to inputs within a specified time constraint.

## S

**Sensor Fusion**: The process of combining data from multiple sensors to achieve better accuracy and reliability.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location.

**Social Robot**: A robot that interacts with humans using social signals and behaviors.

**Stability**: The ability of a system to maintain its state when subjected to disturbances.

**Static Balance**: Maintaining balance while not moving.

**Stereovision**: The process of extracting 3D information from digital images taken from two or more cameras.

## T

**Task Space**: The space in which the task is naturally described, typically Cartesian space for manipulation tasks.

**Teleoperation**: The remote operation of a robot by a human operator.

**Trajectory Planning**: The process of creating a path that a robot will follow over time.

**Transform**: In robotics, the mathematical representation of the position and orientation of one coordinate frame relative to another.

## U

**Unified Robot Description Format (URDF)**: An XML format for representing a robot model including kinematics, dynamics, and visual properties.

**User Interface**: The means by which a person interacts with a robot.

## V

**Visual SLAM**: SLAM that uses visual sensors (cameras) as the primary sensor modality.

**Vision-Language-Action (VLA)**: Systems that integrate visual perception, language understanding, and physical action.

**Voxel**: A volume element, representing a value on a regular grid in three-dimensional space.

## W

**Whisper**: OpenAI's automatic speech recognition system.

**Whole-Body Control**: A control approach that considers the entire robot as a single system rather than controlling parts independently.

**Workspace**: The space in which a robot can operate, either physically or functionally.

## Y

**Yaw**: Rotation around the vertical axis of a robot.

## Z

**ZMP (Zero Moment Point)**: A point on the ground where the sum of all moments of the active forces equals zero, important for bipedal stability.

## Common Acronyms

- **AI**: Artificial Intelligence
- **API**: Application Programming Interface
- **CPU**: Central Processing Unit
- **DOF**: Degrees of Freedom
- **GPU**: Graphics Processing Unit
- **HRI**: Human-Robot Interaction
- **IMU**: Inertial Measurement Unit
- **IoT**: Internet of Things
- **LLM**: Large Language Model
- **ML**: Machine Learning
- **NLP**: Natural Language Processing
- **PID**: Proportional-Integral-Derivative
- **QoS**: Quality of Service
- **ROS**: Robot Operating System
- **SLAM**: Simultaneous Localization and Mapping
- **URDF**: Unified Robot Description Format
- **VLA**: Vision-Language-Action
- **ZMP**: Zero Moment Point