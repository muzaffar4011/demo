"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[1336],{8453(n,e,s){s.d(e,{R:()=>r,x:()=>t});var i=s(6540);const a={},o=i.createContext(a);function r(n){const e=i.useContext(o);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:r(n.components),i.createElement(o.Provider,{value:e},n.children)}},9342(n,e,s){s.r(e),s.d(e,{assets:()=>l,contentTitle:()=>t,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-2/sensors","title":"Sensors","description":"Sensors are crucial components of digital twins, providing the data needed for perception, navigation, and control in humanoid robotics applications. This lesson covers the integration of various sensor types in simulation environments.","source":"@site/docs/module-2/sensors.md","sourceDirName":"module-2","slug":"/module-2/sensors","permalink":"/physical-ai-humanoid-robotics/docs/module-2/sensors","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/physical-ai-humanoid-robotics/edit/main/docusaurus/docs/module-2/sensors.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Sensors"},"sidebar":"tutorialSidebar","previous":{"title":"Rendering","permalink":"/physical-ai-humanoid-robotics/docs/module-2/rendering"},"next":{"title":"Module 3 - The AI-Robot Brain (NVIDIA Isaac\u2122)","permalink":"/physical-ai-humanoid-robotics/docs/module-3/"}}');var a=s(4848),o=s(8453);const r={sidebar_position:5,title:"Sensors"},t="Sensor Integration in Simulation",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Sensor Simulation",id:"introduction-to-sensor-simulation",level:2},{value:"LiDAR Sensors",id:"lidar-sensors",level:2},{value:"Configuration Example",id:"configuration-example",level:3},{value:"3D LiDAR Configuration",id:"3d-lidar-configuration",level:3},{value:"Camera Sensors",id:"camera-sensors",level:2},{value:"RGB Camera Configuration",id:"rgb-camera-configuration",level:3},{value:"Depth Camera Configuration",id:"depth-camera-configuration",level:3},{value:"IMU Sensors",id:"imu-sensors",level:2},{value:"Configuration for Humanoid Balance",id:"configuration-for-humanoid-balance",level:3},{value:"Force/Torque Sensors",id:"forcetorque-sensors",level:2},{value:"Joint Force/Torque Sensors",id:"joint-forcetorque-sensors",level:3},{value:"GPS Sensors (for outdoor humanoid robots)",id:"gps-sensors-for-outdoor-humanoid-robots",level:2},{value:"Sensor Placement for Humanoid Robots",id:"sensor-placement-for-humanoid-robots",level:2},{value:"Head-Mounted Sensors",id:"head-mounted-sensors",level:3},{value:"Body-Mounted Sensors",id:"body-mounted-sensors",level:3},{value:"Joint Sensors",id:"joint-sensors",level:3},{value:"Sensor Fusion in Simulation",id:"sensor-fusion-in-simulation",level:2},{value:"Example: IMU and Camera Fusion",id:"example-imu-and-camera-fusion",level:3},{value:"Sensor Calibration in Simulation",id:"sensor-calibration-in-simulation",level:2},{value:"Simulated Calibration Process",id:"simulated-calibration-process",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Sensor Update Rates",id:"sensor-update-rates",level:3},{value:"Computational Load",id:"computational-load",level:3},{value:"Sensor Validation Techniques",id:"sensor-validation-techniques",level:2},{value:"Data Quality Checks",id:"data-quality-checks",level:3},{value:"Simulation vs. Reality Comparison",id:"simulation-vs-reality-comparison",level:3},{value:"Common Sensor Issues in Simulation",id:"common-sensor-issues-in-simulation",level:2},{value:"Noise Modeling",id:"noise-modeling",level:3},{value:"Synchronization",id:"synchronization",level:3},{value:"Advanced Sensor Techniques",id:"advanced-sensor-techniques",level:2},{value:"Multi-sensor Arrays",id:"multi-sensor-arrays",level:3},{value:"Dynamic Sensor Configuration",id:"dynamic-sensor-configuration",level:3},{value:"Exercise",id:"exercise",level:2},{value:"Summary",id:"summary",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"sensor-integration-in-simulation",children:"Sensor Integration in Simulation"})}),"\n",(0,a.jsx)(e.p,{children:"Sensors are crucial components of digital twins, providing the data needed for perception, navigation, and control in humanoid robotics applications. This lesson covers the integration of various sensor types in simulation environments."}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"After completing this lesson, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Integrate different types of sensors in humanoid robot simulation"}),"\n",(0,a.jsx)(e.li,{children:"Configure sensor parameters for realistic data generation"}),"\n",(0,a.jsx)(e.li,{children:"Implement sensor fusion techniques in simulation"}),"\n",(0,a.jsx)(e.li,{children:"Validate sensor data accuracy and timing"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"introduction-to-sensor-simulation",children:"Introduction to Sensor Simulation"}),"\n",(0,a.jsx)(e.p,{children:"In digital twin environments, sensors must accurately simulate their real-world counterparts:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"LiDAR"}),": Distance measurement and environment mapping"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Cameras"}),": Visual perception and object recognition"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"IMUs"}),": Inertial measurement for orientation and acceleration"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Force/Torque sensors"}),": Contact forces and joint loads"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"GPS"}),": Global positioning (for outdoor robots)"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"For humanoid robots, sensor placement is critical for:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Balance and stability control"}),"\n",(0,a.jsx)(e.li,{children:"Environment perception and navigation"}),"\n",(0,a.jsx)(e.li,{children:"Human-robot interaction"}),"\n",(0,a.jsx)(e.li,{children:"Safe operation in human environments"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"lidar-sensors",children:"LiDAR Sensors"}),"\n",(0,a.jsx)(e.h3,{id:"configuration-example",children:"Configuration Example"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<model name="humanoid_robot">\n  <link name="lidar_link">\n    <sensor name="lidar_2d" type="ray">\n      <ray>\n        <scan>\n          <horizontal>\n            <samples>720</samples>\n            <resolution>1</resolution>\n            <min_angle>-3.14159</min_angle>  \x3c!-- -\u03c0 --\x3e\n            <max_angle>3.14159</max_angle>    \x3c!-- \u03c0 --\x3e\n          </horizontal>\n        </scan>\n        <range>\n          <min>0.1</min>\n          <max>30.0</max>\n          <resolution>0.01</resolution>\n        </range>\n      </ray>\n      <always_on>1</always_on>\n      <update_rate>10</update_rate>\n      <visualize>true</visualize>\n    </sensor>\n  </link>\n</model>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"3d-lidar-configuration",children:"3D LiDAR Configuration"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<sensor name="lidar_3d" type="ray">\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>640</samples>\n        <resolution>1</resolution>\n        <min_angle>-2.35619</min_angle>  \x3c!-- -135\xb0 --\x3e\n        <max_angle>2.35619</max_angle>   \x3c!-- 135\xb0 --\x3e\n      </horizontal>\n      <vertical>\n        <samples>64</samples>\n        <resolution>1</resolution>\n        <min_angle>-0.2618</min_angle>   \x3c!-- -15\xb0 --\x3e\n        <max_angle>0.2618</max_angle>    \x3c!-- 15\xb0 --\x3e\n      </vertical>\n    </scan>\n    <range>\n      <min>0.1</min>\n      <max>100.0</max>\n      <resolution>0.01</resolution>\n    </range>\n  </ray>\n  <always_on>1</always_on>\n  <update_rate>10</update_rate>\n  <visualize>true</visualize>\n</sensor>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"camera-sensors",children:"Camera Sensors"}),"\n",(0,a.jsx)(e.h3,{id:"rgb-camera-configuration",children:"RGB Camera Configuration"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<sensor name="rgb_camera" type="camera">\n  <camera name="head_camera">\n    <horizontal_fov>1.0472</horizontal_fov>  \x3c!-- 60 degrees --\x3e\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n    <clip>\n      <near>0.1</near>\n      <far>100</far>\n    </clip>\n    <noise>\n      <type>gaussian</type>\n      <mean>0.0</mean>\n      <stddev>0.007</stddev>\n    </noise>\n  </camera>\n  <always_on>1</always_on>\n  <update_rate>30</update_rate>\n  <visualize>true</visualize>\n</sensor>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"depth-camera-configuration",children:"Depth Camera Configuration"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<sensor name="depth_camera" type="depth">\n  <camera name="depth_cam">\n    <horizontal_fov>1.0472</horizontal_fov>\n    <image>\n      <width>640</width>\n      <height>480</height>\n    </image>\n    <clip>\n      <near>0.1</near>\n      <far>10</far>\n    </clip>\n  </camera>\n  <always_on>1</always_on>\n  <update_rate>30</update_rate>\n  <visualize>true</visualize>\n</sensor>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"imu-sensors",children:"IMU Sensors"}),"\n",(0,a.jsx)(e.h3,{id:"configuration-for-humanoid-balance",children:"Configuration for Humanoid Balance"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\n  <always_on>1</always_on>\n  <update_rate>100</update_rate>\n  <imu>\n    <angular_velocity>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.0017</stddev>\n          <bias_mean>0.0001</bias_mean>\n          <bias_stddev>0.0005</bias_stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.0017</stddev>\n          <bias_mean>0.0001</bias_mean>\n          <bias_stddev>0.0005</bias_stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.0017</stddev>\n          <bias_mean>0.0001</bias_mean>\n          <bias_stddev>0.0005</bias_stddev>\n        </noise>\n      </z>\n    </angular_velocity>\n    <linear_acceleration>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n          <bias_mean>0.001</bias_mean>\n          <bias_stddev>0.005</bias_stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n          <bias_mean>0.001</bias_mean>\n          <bias_stddev>0.005</bias_stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n          <bias_mean>0.001</bias_mean>\n          <bias_stddev>0.005</bias_stddev>\n        </noise>\n      </z>\n    </linear_acceleration>\n  </imu>\n</sensor>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"forcetorque-sensors",children:"Force/Torque Sensors"}),"\n",(0,a.jsx)(e.h3,{id:"joint-forcetorque-sensors",children:"Joint Force/Torque Sensors"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<sensor name="left_ankle_ft" type="force_torque">\n  <always_on>1</always_on>\n  <update_rate>100</update_rate>\n  <force_torque>\n    <frame>child</frame>\n    <measure_direction>child_to_parent</measure_direction>\n  </force_torque>\n</sensor>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"gps-sensors-for-outdoor-humanoid-robots",children:"GPS Sensors (for outdoor humanoid robots)"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<sensor name="gps_sensor" type="gps">\n  <always_on>1</always_on>\n  <update_rate>1</update_rate>\n  <gps>\n    <position_sensing>\n      <horizontal>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.2</stddev>\n        </noise>\n      </horizontal>\n      <vertical>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.3</stddev>\n        </noise>\n      </vertical>\n    </position_sensing>\n  </gps>\n</sensor>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"sensor-placement-for-humanoid-robots",children:"Sensor Placement for Humanoid Robots"}),"\n",(0,a.jsx)(e.h3,{id:"head-mounted-sensors",children:"Head-Mounted Sensors"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Stereo cameras"}),": For depth perception and object recognition"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Microphones"}),": For voice interaction and sound localization"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Infrared sensors"}),": For close-range obstacle detection"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"body-mounted-sensors",children:"Body-Mounted Sensors"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"IMUs"}),": In torso for balance control, in limbs for motion tracking"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Force sensors"}),": In feet for balance, in hands for manipulation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Tactile sensors"}),": In hands and feet for contact feedback"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"joint-sensors",children:"Joint Sensors"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Encoders"}),": For precise joint angle measurement"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Torque sensors"}),": For force control and safety"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"sensor-fusion-in-simulation",children:"Sensor Fusion in Simulation"}),"\n",(0,a.jsx)(e.h3,{id:"example-imu-and-camera-fusion",children:"Example: IMU and Camera Fusion"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Imu, Image\nfrom geometry_msgs.msg import Vector3\nfrom cv_bridge import CvBridge\nimport numpy as np\n\nclass SensorFusionNode(Node):\n    def __init__(self):\n        super().__init__('sensor_fusion_node')\n\n        # Subscribers for IMU and camera\n        self.imu_sub = self.create_subscription(Imu, 'imu/data', self.imu_callback, 10)\n        self.camera_sub = self.create_subscription(Image, 'camera/image_raw', self.camera_callback, 10)\n\n        # Publisher for fused data\n        self.fused_pub = self.create_publisher(Vector3, 'fused_orientation', 10)\n\n        self.bridge = CvBridge()\n        self.latest_imu = None\n\n    def imu_callback(self, msg):\n        self.latest_imu = msg\n        if hasattr(self, 'latest_image'):\n            self.perform_fusion()\n\n    def camera_callback(self, msg):\n        self.latest_image = msg\n        if self.latest_imu:\n            self.perform_fusion()\n\n    def perform_fusion(self):\n        # Simple sensor fusion example\n        if self.latest_imu:\n            # Extract orientation from IMU\n            orientation = self.latest_imu.orientation\n            fused_data = Vector3()\n            fused_data.x = orientation.x\n            fused_data.y = orientation.y\n            fused_data.z = orientation.z\n\n            self.fused_pub.publish(fused_data)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    sensor_fusion_node = SensorFusionNode()\n\n    try:\n        rclpy.spin(sensor_fusion_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        sensor_fusion_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,a.jsx)(e.h2,{id:"sensor-calibration-in-simulation",children:"Sensor Calibration in Simulation"}),"\n",(0,a.jsx)(e.h3,{id:"simulated-calibration-process",children:"Simulated Calibration Process"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<sensor name="calibrated_camera" type="camera">\n  <camera name="calib_cam">\n    <intrinsics>\n      <fx>525.0</fx>\n      <fy>525.0</fy>\n      <cx>319.5</cx>\n      <cy>239.5</cy>\n    </intrinsics>\n    <distortion>\n      <k1>0.0</k1>\n      <k2>0.0</k2>\n      <k3>0.0</k3>\n      <p1>0.0</p1>\n      <p2>0.0</p2>\n    </distortion>\n  </camera>\n</sensor>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,a.jsx)(e.h3,{id:"sensor-update-rates",children:"Sensor Update Rates"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"High-rate sensors"})," (IMU, encoders): 100-1000 Hz"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Medium-rate sensors"})," (cameras): 30-60 Hz"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Low-rate sensors"})," (GPS): 1-10 Hz"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"computational-load",children:"Computational Load"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"LiDAR"}),": High computational cost, especially 3D"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Cameras"}),": Moderate to high depending on resolution and processing"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"IMU"}),": Low computational cost"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Force/Torque"}),": Low computational cost"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"sensor-validation-techniques",children:"Sensor Validation Techniques"}),"\n",(0,a.jsx)(e.h3,{id:"data-quality-checks",children:"Data Quality Checks"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Range validation"}),": Ensure sensor readings are within expected ranges"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Temporal consistency"}),": Check for sudden jumps in sensor data"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Cross-validation"}),": Compare readings from redundant sensors"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Physical plausibility"}),": Verify readings match physical constraints"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"simulation-vs-reality-comparison",children:"Simulation vs. Reality Comparison"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Compare noise characteristics"}),"\n",(0,a.jsx)(e.li,{children:"Validate timing and synchronization"}),"\n",(0,a.jsx)(e.li,{children:"Check for systematic biases"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"common-sensor-issues-in-simulation",children:"Common Sensor Issues in Simulation"}),"\n",(0,a.jsx)(e.h3,{id:"noise-modeling",children:"Noise Modeling"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Underestimated noise"}),": Leads to overconfident perception"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Overestimated noise"}),": Reduces sensor effectiveness"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Non-Gaussian noise"}),": Can cause filter divergence"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"synchronization",children:"Synchronization"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Timestamp accuracy"}),": Critical for sensor fusion"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Update rate mismatches"}),": Can cause integration issues"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Latency modeling"}),": Important for realistic control"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"advanced-sensor-techniques",children:"Advanced Sensor Techniques"}),"\n",(0,a.jsx)(e.h3,{id:"multi-sensor-arrays",children:"Multi-sensor Arrays"}),"\n",(0,a.jsx)(e.p,{children:"For redundancy and enhanced perception:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'\x3c!-- Stereo camera setup --\x3e\n<sensor name="left_camera" type="camera">\n  \x3c!-- Configuration --\x3e\n</sensor>\n<sensor name="right_camera" type="camera">\n  \x3c!-- Configuration with baseline offset --\x3e\n</sensor>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"dynamic-sensor-configuration",children:"Dynamic Sensor Configuration"}),"\n",(0,a.jsx)(e.p,{children:"Change sensor parameters based on robot state:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<gazebo>\n  <plugin name="dynamic_sensor_plugin" filename="libDynamicSensorPlugin.so">\n    <topic>sensor_config</topic>\n    <default_rate>30</default_rate>\n    <active_rate>60</active_rate>\n  </plugin>\n</gazebo>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"exercise",children:"Exercise"}),"\n",(0,a.jsx)(e.p,{children:"Create a humanoid robot model with:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"LiDAR sensor for environment mapping"}),"\n",(0,a.jsx)(e.li,{children:"Stereo cameras for depth perception"}),"\n",(0,a.jsx)(e.li,{children:"IMU sensors for balance control"}),"\n",(0,a.jsx)(e.li,{children:"Force/torque sensors in feet for ground contact detection"}),"\n",(0,a.jsx)(e.li,{children:"Implement a simple sensor fusion node that combines IMU and camera data"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(e.p,{children:"Sensor integration is crucial for realistic digital twin development in humanoid robotics. Proper configuration of sensor parameters, placement, and fusion techniques enables effective perception and control in simulation environments. The next module will cover the AI-Robot Brain systems using NVIDIA Isaac."})]})}function u(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(c,{...n})}):c(n)}}}]);