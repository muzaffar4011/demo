"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[8256],{1575(n,e,a){a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>t,toc:()=>p});const t=JSON.parse('{"id":"module-3/nav2-bipedal","title":"Nav2 Bipedal Planning","description":"Navigation 2 (Nav2) is the ROS 2 navigation stack that provides path planning and navigation capabilities. For humanoid robots, Nav2 requires special configuration to handle bipedal locomotion patterns and unique mobility constraints.","source":"@site/docs/module-3/nav2-bipedal.md","sourceDirName":"module-3","slug":"/module-3/nav2-bipedal","permalink":"/physical-ai-humanoid-robotics/docs/module-3/nav2-bipedal","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/physical-ai-humanoid-robotics/edit/main/docusaurus/docs/module-3/nav2-bipedal.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Nav2 Bipedal Planning"},"sidebar":"tutorialSidebar","previous":{"title":"VSLAM Navigation","permalink":"/physical-ai-humanoid-robotics/docs/module-3/vslam-navigation"},"next":{"title":"Module 4 - Vision-Language-Action (VLA)","permalink":"/physical-ai-humanoid-robotics/docs/module-4/"}}');var o=a(4848),i=a(8453);const s={sidebar_position:4,title:"Nav2 Bipedal Planning"},r="Nav2 for Bipedal Path Planning",l={},p=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Humanoid Navigation Challenges",id:"introduction-to-humanoid-navigation-challenges",level:2},{value:"Nav2 Architecture for Humanoid Robots",id:"nav2-architecture-for-humanoid-robots",level:2},{value:"Custom Costmap Configuration",id:"custom-costmap-configuration",level:3},{value:"Footstep Planning for Bipedal Robots",id:"footstep-planning-for-bipedal-robots",level:2},{value:"Custom Footstep Planner",id:"custom-footstep-planner",level:3},{value:"Custom Controllers for Humanoid Walking",id:"custom-controllers-for-humanoid-walking",level:2},{value:"Walking Pattern Generator",id:"walking-pattern-generator",level:3},{value:"Behavior Trees for Humanoid Navigation",id:"behavior-trees-for-humanoid-navigation",level:2},{value:"Custom Behavior Tree Nodes",id:"custom-behavior-tree-nodes",level:3},{value:"Human-Aware Navigation",id:"human-aware-navigation",level:2},{value:"Social Navigation Parameters",id:"social-navigation-parameters",level:3},{value:"Terrain Adaptation for Humanoid Navigation",id:"terrain-adaptation-for-humanoid-navigation",level:2},{value:"Stair and Slope Navigation",id:"stair-and-slope-navigation",level:3},{value:"Performance Optimization for Humanoid Navigation",id:"performance-optimization-for-humanoid-navigation",level:2},{value:"Real-time Considerations",id:"real-time-considerations",level:3},{value:"Exercise",id:"exercise",level:2},{value:"Summary",id:"summary",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"nav2-for-bipedal-path-planning",children:"Nav2 for Bipedal Path Planning"})}),"\n",(0,o.jsx)(e.p,{children:"Navigation 2 (Nav2) is the ROS 2 navigation stack that provides path planning and navigation capabilities. For humanoid robots, Nav2 requires special configuration to handle bipedal locomotion patterns and unique mobility constraints."}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(e.p,{children:"After completing this lesson, you will be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Configure Nav2 for humanoid robot navigation"}),"\n",(0,o.jsx)(e.li,{children:"Adapt path planning algorithms for bipedal locomotion"}),"\n",(0,o.jsx)(e.li,{children:"Implement custom controllers for humanoid walking patterns"}),"\n",(0,o.jsx)(e.li,{children:"Integrate Nav2 with humanoid-specific perception systems"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"introduction-to-humanoid-navigation-challenges",children:"Introduction to Humanoid Navigation Challenges"}),"\n",(0,o.jsx)(e.p,{children:"Bipedal navigation presents unique challenges compared to wheeled robots:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Balance constraints"}),": Limited to specific foot placements"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Dynamic stability"}),": Requires continuous balance control"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Footstep planning"}),": Must plan discrete footstep locations"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Terrain adaptability"}),": Need to handle stairs, slopes, and uneven surfaces"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Human-aware navigation"}),": Must navigate safely around humans"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"nav2-architecture-for-humanoid-robots",children:"Nav2 Architecture for Humanoid Robots"}),"\n",(0,o.jsx)(e.h3,{id:"custom-costmap-configuration",children:"Custom Costmap Configuration"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid robots need specialized costmaps that consider:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Traversable terrain for bipedal locomotion"}),"\n",(0,o.jsx)(e.li,{children:"Step height and width constraints"}),"\n",(0,o.jsx)(e.li,{children:"Balance and stability requirements"}),"\n"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-yaml",children:'# Costmap configuration for humanoid robot\nglobal_costmap:\n  global_costmap:\n    ros__parameters:\n      update_frequency: 5.0\n      publish_frequency: 2.0\n      global_frame: map\n      robot_base_frame: base_link\n      use_sim_time: true\n      rolling_window: false\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\n\n      static_layer:\n        plugin: "nav2_costmap_2d::StaticLayer"\n        map_topic: "map"\n        transform_tolerance: 0.2\n        map_subscribe_transient_local: true\n\n      obstacle_layer:\n        plugin: "nav2_costmap_2d::ObstacleLayer"\n        enabled: True\n        observation_sources: scan\n        scan:\n          topic: /scan\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.50\n        inflate_to_robot_footprint: false\n\nlocal_costmap:\n  local_costmap:\n    ros__parameters:\n      update_frequency: 5.0\n      publish_frequency: 2.0\n      global_frame: odom\n      robot_base_frame: base_link\n      rolling_window: true\n      width: 6\n      height: 6\n      resolution: 0.05\n      use_sim_time: true\n      plugins: ["obstacle_layer", "voxel_layer", "inflation_layer"]\n\n      obstacle_layer:\n        plugin: "nav2_costmap_2d::ObstacleLayer"\n        enabled: True\n        observation_sources: scan\n        scan:\n          topic: /scan\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n\n      voxel_layer:\n        plugin: "nav2_costmap_2d::VoxelLayer"\n        enabled: True\n        publish_voxel_map: True\n        origin_z: 0.0\n        z_resolution: 0.2\n        z_voxels: 10\n        max_obstacle_height: 2.0\n        mark_threshold: 0\n        observation_sources: pointcloud\n        pointcloud:\n          topic: /camera/depth/points\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "PointCloud2"\n          min_obstacle_height: 0.0\n          obstacle_range: 2.5\n          raytrace_range: 3.0\n\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.30\n'})}),"\n",(0,o.jsx)(e.h2,{id:"footstep-planning-for-bipedal-robots",children:"Footstep Planning for Bipedal Robots"}),"\n",(0,o.jsx)(e.h3,{id:"custom-footstep-planner",children:"Custom Footstep Planner"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom nav_msgs.msg import Path\nfrom builtin_interfaces.msg import Duration\nimport numpy as np\n\nclass FootstepPlanner(Node):\n    def __init__(self):\n        super().__init__(\'footstep_planner\')\n\n        self.path_sub = self.create_subscription(\n            Path,\n            \'/plan\',\n            self.path_callback,\n            10\n        )\n\n        self.footstep_pub = self.create_publisher(\n            Path,\n            \'/footstep_plan\',\n            10\n        )\n\n        # Humanoid-specific parameters\n        self.step_length = 0.3  # meters\n        self.step_width = 0.2   # meters\n        self.step_height = 0.05 # meters (for stepping over obstacles)\n\n    def path_callback(self, msg):\n        """Convert continuous path to discrete footsteps"""\n        footstep_path = Path()\n        footstep_path.header = msg.header\n\n        # Generate footsteps along the path\n        footsteps = self.generate_footsteps(msg.poses)\n\n        for footstep in footsteps:\n            pose_stamped = PoseStamped()\n            pose_stamped.header = msg.header\n            pose_stamped.pose = footstep\n            footstep_path.poses.append(pose_stamped)\n\n        self.footstep_pub.publish(footstep_path)\n\n    def generate_footsteps(self, path_poses):\n        """Generate discrete footsteps from continuous path"""\n        footsteps = []\n\n        if len(path_poses) < 2:\n            return footsteps\n\n        # Start with current position\n        current_pos = path_poses[0].pose.position\n        footsteps.append(path_poses[0].pose)\n\n        # Generate footsteps along the path\n        for i in range(1, len(path_poses)):\n            target_pos = path_poses[i].pose.position\n\n            # Calculate direction and distance\n            dx = target_pos.x - current_pos.x\n            dy = target_pos.y - current_pos.y\n            distance = np.sqrt(dx*dx + dy*dy)\n\n            # Generate intermediate footsteps if needed\n            if distance > self.step_length:\n                num_steps = int(distance / self.step_length)\n\n                for j in range(1, num_steps + 1):\n                    ratio = j / num_steps\n                    step_x = current_pos.x + ratio * dx\n                    step_y = current_pos.y + ratio * dy\n\n                    step_pose = path_poses[i].pose\n                    step_pose.position.x = step_x\n                    step_pose.position.y = step_y\n                    footsteps.append(step_pose)\n\n            current_pos = target_pos\n\n        return footsteps\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = FootstepPlanner()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"custom-controllers-for-humanoid-walking",children:"Custom Controllers for Humanoid Walking"}),"\n",(0,o.jsx)(e.h3,{id:"walking-pattern-generator",children:"Walking Pattern Generator"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, Pose\nfrom sensor_msgs.msg import JointState\nimport numpy as np\n\nclass HumanoidWalkingController(Node):\n    def __init__(self):\n        super().__init__('humanoid_walking_controller')\n\n        self.cmd_vel_sub = self.create_subscription(\n            Twist,\n            '/cmd_vel',\n            self.cmd_vel_callback,\n            10\n        )\n\n        self.joint_cmd_pub = self.create_publisher(\n            JointState,\n            '/joint_commands',\n            10\n        )\n\n        # Walking parameters\n        self.step_frequency = 1.0  # steps per second\n        self.step_length = 0.3     # meters\n        self.step_height = 0.05    # meters\n\n        # Timer for walking pattern generation\n        self.timer = self.create_timer(0.02, self.generate_walking_pattern)  # 50Hz\n\n        self.current_vel = Twist()\n        self.phase = 0.0\n\n    def cmd_vel_callback(self, msg):\n        \"\"\"Update walking velocity\"\"\"\n        self.current_vel = msg\n\n    def generate_walking_pattern(self):\n        \"\"\"Generate walking joint commands based on velocity\"\"\"\n        joint_state = JointState()\n        joint_state.name = [\n            'left_hip_roll', 'left_hip_yaw', 'left_hip_pitch',\n            'left_knee', 'left_ankle_pitch', 'left_ankle_roll',\n            'right_hip_roll', 'right_hip_yaw', 'right_hip_pitch',\n            'right_knee', 'right_ankle_pitch', 'right_ankle_roll'\n        ]\n\n        # Generate walking pattern based on desired velocity\n        # This is a simplified example - real implementation would be more complex\n        joint_positions = self.calculate_joint_positions()\n        joint_state.position = joint_positions\n\n        # Add timing information\n        joint_state.header.stamp = self.get_clock().now().to_msg()\n\n        self.joint_cmd_pub.publish(joint_state)\n\n    def calculate_joint_positions(self):\n        \"\"\"Calculate joint positions for walking pattern\"\"\"\n        # Simplified walking pattern calculation\n        # In practice, this would use inverse kinematics and dynamic balance\n\n        # Calculate phase based on time and step frequency\n        self.phase += 0.02 * self.step_frequency * 2 * np.pi\n\n        # Calculate walking pattern based on phase\n        left_leg = self.calculate_leg_position('left', self.phase)\n        right_leg = self.calculate_leg_position('right', self.phase + np.pi)\n\n        # Combine with torso and arm positions\n        positions = left_leg + [0.0, 0.0, 0.0] + right_leg + [0.0, 0.0, 0.0]\n\n        return positions\n\n    def calculate_leg_position(self, side, phase):\n        \"\"\"Calculate joint positions for a leg based on walking phase\"\"\"\n        # Simplified leg position calculation\n        # Real implementation would include balance control\n        hip_pitch = 0.1 * np.sin(phase) if side == 'left' else 0.1 * np.sin(phase)\n        knee = 0.2 * np.cos(phase)\n        ankle = -0.1 * np.sin(phase)\n\n        return [0.0, 0.0, hip_pitch, knee, ankle, 0.0]\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = HumanoidWalkingController()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(e.h2,{id:"behavior-trees-for-humanoid-navigation",children:"Behavior Trees for Humanoid Navigation"}),"\n",(0,o.jsx)(e.h3,{id:"custom-behavior-tree-nodes",children:"Custom Behavior Tree Nodes"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-xml",children:'\x3c!-- Example behavior tree for humanoid navigation --\x3e\n<root main_tree_to_execute="MainTree">\n    <BehaviorTree ID="MainTree">\n        <RecoveryNode number_of_retries="6" name="NavigateRecovery">\n            <PipelineSequence name="NavigateWithReplanning">\n                <RateController hz="1.0">\n                    <ComputePathToPose goal="{goal}" path="{path}" planner_id="GridBased"/>\n                </RateController>\n                <SmoothPath path="{path}" output_path="{smoothed_path}" max_vel="0.3" max_acc="0.5"/>\n                <TruncatePath path="{smoothed_path}" distance="1.0" output_path="{truncated_path}"/>\n                <RemovePassedGoals goal="{goal}" path="{truncated_path}" output_goal="{updated_goal}"/>\n                <FollowPath path="{truncated_path}" controller_id="FollowPath"/>\n            </PipelineSequence>\n            <ReactiveFallback name="RecoveryFallback">\n                <ClearEntireCostmap name="ClearLocalCostmap" service_name="local_costmap/clear_entirely_local_costmap"/>\n                <ClearEntireCostmap name="ClearGlobalCostmap" service_name="global_costmap/clear_entirely_global_costmap"/>\n                <BackUp backup_dist="0.30" backup_speed="0.05" name="Backup"/>\n                <Spin spin_dist="1.57" name="Spin"/>\n                <Wait wait_duration="5" name="Wait"/>\n            </ReactiveFallback>\n        </RecoveryNode>\n    </BehaviorTree>\n</root>\n'})}),"\n",(0,o.jsx)(e.h2,{id:"human-aware-navigation",children:"Human-Aware Navigation"}),"\n",(0,o.jsx)(e.h3,{id:"social-navigation-parameters",children:"Social Navigation Parameters"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-yaml",children:'# Social navigation configuration\nlocal_costmap:\n  local_costmap:\n    ros__parameters:\n      plugins: ["obstacle_layer", "voxel_layer", "social_layer", "inflation_layer"]\n\n      social_layer:\n        plugin: "nav2_social_layer::SocialLayer"\n        enabled: True\n        observation_sources: people\n        people:\n          topic: /people_positions\n          max_obstacle_height: 2.0\n          clearing: False\n          marking: True\n          data_type: "PointCloud2"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.5\n'})}),"\n",(0,o.jsx)(e.h2,{id:"terrain-adaptation-for-humanoid-navigation",children:"Terrain Adaptation for Humanoid Navigation"}),"\n",(0,o.jsx)(e.h3,{id:"stair-and-slope-navigation",children:"Stair and Slope Navigation"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import PointCloud2\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import Bool\nimport numpy as np\nfrom scipy import ndimage\n\nclass TerrainAnalyzer(Node):\n    def __init__(self):\n        super().__init__(\'terrain_analyzer\')\n\n        self.pointcloud_sub = self.create_subscription(\n            PointCloud2,\n            \'/camera/depth/points\',\n            self.pointcloud_callback,\n            10\n        )\n\n        self.stair_pub = self.create_publisher(\n            Bool,\n            \'/terrain/stairs_detected\',\n            10\n        )\n\n        self.slope_pub = self.create_publisher(\n            Bool,\n            \'/terrain/slope_detected\',\n            10\n        )\n\n    def pointcloud_callback(self, msg):\n        """Analyze terrain for stairs and slopes"""\n        # Convert PointCloud2 to numpy array\n        # This is a simplified example\n        terrain_data = self.process_pointcloud(msg)\n\n        # Analyze for stairs\n        stairs_detected = self.detect_stairs(terrain_data)\n        self.stair_pub.publish(Bool(data=stairs_detected))\n\n        # Analyze for slopes\n        slope_detected = self.detect_slope(terrain_data)\n        self.slope_pub.publish(Bool(data=slope_detected))\n\n    def detect_stairs(self, terrain_data):\n        """Detect stairs in terrain data"""\n        # Simple stair detection algorithm\n        # In practice, this would use more sophisticated methods\n        if terrain_data is not None:\n            # Look for step-like patterns in elevation data\n            elevation_changes = np.diff(terrain_data, axis=0)\n            step_count = np.sum(np.abs(elevation_changes) > 0.15)  # 15cm steps\n            return step_count > 2\n        return False\n\n    def detect_slope(self, terrain_data):\n        """Detect slopes in terrain data"""\n        if terrain_data is not None:\n            # Calculate terrain gradient\n            grad_x, grad_y = np.gradient(terrain_data)\n            slope_angle = np.arctan(np.sqrt(grad_x**2 + grad_y**2))\n            max_slope = np.max(slope_angle)\n            # Return True if slope is above 15 degrees\n            return np.rad2deg(max_slope) > 15\n        return False\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = TerrainAnalyzer()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"performance-optimization-for-humanoid-navigation",children:"Performance Optimization for Humanoid Navigation"}),"\n",(0,o.jsx)(e.h3,{id:"real-time-considerations",children:"Real-time Considerations"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-yaml",children:'# Optimized parameters for real-time humanoid navigation\nplanner_server:\n  ros__parameters:\n    expected_planner_frequency: 1.0  # Lower frequency for complex planning\n    use_sim_time: true\n    planner_plugins: ["GridBased"]\n    GridBased:\n      plugin: "nav2_navfn_planner/NavfnPlanner"\n      tolerance: 0.5\n      use_astar: false\n      allow_unknown: true\n\ncontroller_server:\n  ros__parameters:\n    controller_frequency: 20.0      # Higher frequency for balance\n    min_x_velocity_threshold: 0.01\n    min_y_velocity_threshold: 0.01\n    min_theta_velocity_threshold: 0.01\n    progress_checker_plugin: "progress_checker"\n    goal_checker_plugin: "goal_checker"\n    controller_plugins: ["FollowPath"]\n\n    FollowPath:\n      plugin: "nav2_mppi_controller/MppiController"\n      time_steps: 20\n      control_frequency: 20.0\n      batch_size: 2000\n      model_dt: 0.05\n      wheels_separation: 0.3\n      wheels_radius: 0.1\n'})}),"\n",(0,o.jsx)(e.h2,{id:"exercise",children:"Exercise"}),"\n",(0,o.jsx)(e.p,{children:"Configure Nav2 for a humanoid robot with:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Custom costmap layers for bipedal navigation"}),"\n",(0,o.jsx)(e.li,{children:"Footstep planner that converts continuous paths to discrete steps"}),"\n",(0,o.jsx)(e.li,{children:"Walking controller that generates appropriate joint commands"}),"\n",(0,o.jsx)(e.li,{children:"Terrain analysis for stairs and slope detection"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"Nav2 requires significant customization for humanoid robot navigation, including specialized costmaps, footstep planning, and walking controllers. Proper configuration enables safe and effective bipedal navigation in complex environments. The next lesson will cover the Vision-Language-Action systems for humanoid robots."})]})}function d(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(c,{...n})}):c(n)}},8453(n,e,a){a.d(e,{R:()=>s,x:()=>r});var t=a(6540);const o={},i=t.createContext(o);function s(n){const e=t.useContext(i);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),t.createElement(i.Provider,{value:e},n.children)}}}]);