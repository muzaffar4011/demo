"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[9690],{286(n,e,a){a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3/vslam-navigation","title":"VSLAM Navigation","description":"Visual Simultaneous Localization and Mapping (VSLAM) is a critical technology for humanoid robots to understand and navigate their environment using visual sensors. Isaac ROS provides optimized implementations for VSLAM and navigation tasks.","source":"@site/docs/module-3/vslam-navigation.md","sourceDirName":"module-3","slug":"/module-3/vslam-navigation","permalink":"/physical-ai-humanoid-robotics/docs/module-3/vslam-navigation","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/physical-ai-humanoid-robotics/edit/main/docusaurus/docs/module-3/vslam-navigation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"VSLAM Navigation"},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim","permalink":"/physical-ai-humanoid-robotics/docs/module-3/isaac-sim"},"next":{"title":"Nav2 Bipedal Planning","permalink":"/physical-ai-humanoid-robotics/docs/module-3/nav2-bipedal"}}');var o=a(4848),t=a(8453);const s={sidebar_position:3,title:"VSLAM Navigation"},r="Visual SLAM and Navigation with Isaac ROS",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Visual SLAM for Humanoid Robots",id:"introduction-to-visual-slam-for-humanoid-robots",level:2},{value:"Isaac ROS VSLAM Components",id:"isaac-ros-vslam-components",level:2},{value:"Isaac ROS AprilTag Detection",id:"isaac-ros-apriltag-detection",level:3},{value:"Isaac ROS Stereo Dense Reconstruction",id:"isaac-ros-stereo-dense-reconstruction",level:3},{value:"Isaac ROS Navigation Stack",id:"isaac-ros-navigation-stack",level:2},{value:"Basic Navigation Setup",id:"basic-navigation-setup",level:3}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"visual-slam-and-navigation-with-isaac-ros",children:"Visual SLAM and Navigation with Isaac ROS"})}),"\n",(0,o.jsx)(e.p,{children:"Visual Simultaneous Localization and Mapping (VSLAM) is a critical technology for humanoid robots to understand and navigate their environment using visual sensors. Isaac ROS provides optimized implementations for VSLAM and navigation tasks."}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(e.p,{children:"After completing this lesson, you will be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Implement visual SLAM systems using Isaac ROS"}),"\n",(0,o.jsx)(e.li,{children:"Configure navigation pipelines for humanoid robot mobility"}),"\n",(0,o.jsx)(e.li,{children:"Integrate perception and navigation systems"}),"\n",(0,o.jsx)(e.li,{children:"Optimize VSLAM performance for real-time humanoid applications"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"introduction-to-visual-slam-for-humanoid-robots",children:"Introduction to Visual SLAM for Humanoid Robots"}),"\n",(0,o.jsx)(e.p,{children:"Visual SLAM enables humanoid robots to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Build maps of unknown environments"}),"\n",(0,o.jsx)(e.li,{children:"Localize themselves within those maps"}),"\n",(0,o.jsx)(e.li,{children:"Plan paths to navigate safely"}),"\n",(0,o.jsx)(e.li,{children:"Avoid obstacles in real-time"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"For humanoid robots, VSLAM faces unique challenges:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Limited computational resources on humanoid platforms"}),"\n",(0,o.jsx)(e.li,{children:"Dynamic movement affecting camera stability"}),"\n",(0,o.jsx)(e.li,{children:"Complex environments with humans and furniture"}),"\n",(0,o.jsx)(e.li,{children:"Need for real-time performance for safety"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"isaac-ros-vslam-components",children:"Isaac ROS VSLAM Components"}),"\n",(0,o.jsx)(e.h3,{id:"isaac-ros-apriltag-detection",children:"Isaac ROS AprilTag Detection"}),"\n",(0,o.jsx)(e.p,{children:"AprilTags provide precise pose estimation for navigation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# Example AprilTag detection node\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom geometry_msgs.msg import PoseArray\nfrom isaac_ros_apriltag_interfaces.msg import AprilTagDetectionArray\n\nclass AprilTagNavigator(Node):\n    def __init__(self):\n        super().__init__('apriltag_navigator')\n\n        # Subscriptions\n        self.image_sub = self.create_subscription(\n            Image,\n            '/camera/image_rect_color',\n            self.image_callback,\n            10\n        )\n\n        # Publications\n        self.tag_pub = self.create_publisher(\n            AprilTagDetectionArray,\n            '/apriltag_detections',\n            10\n        )\n\n        self.nav_goal_pub = self.create_publisher(\n            PoseArray,\n            '/navigation_goals',\n            10\n        )\n\n    def image_callback(self, msg):\n        # Process image for AprilTag detection\n        # Publish navigation goals based on tag positions\n        pass\n"})}),"\n",(0,o.jsx)(e.h3,{id:"isaac-ros-stereo-dense-reconstruction",children:"Isaac ROS Stereo Dense Reconstruction"}),"\n",(0,o.jsx)(e.p,{children:"For 3D environment understanding:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-yaml",children:'# Stereo Dense Reconstruction configuration\nname: StereoDenseReconstruction\ncomponents:\n  - name: IsaacStereoDenseNetwork\n    parameters:\n      - name: input_left_topic\n        value: "/left/image_rect_color"\n      - name: input_right_topic\n        value: "/right/image_rect_color"\n      - name: output_depth_topic\n        value: "/depth/image_rect_raw"\n      - name: output_confidence_topic\n        value: "/confidence/image_rect_raw"\n'})}),"\n",(0,o.jsx)(e.h2,{id:"isaac-ros-navigation-stack",children:"Isaac ROS Navigation Stack"}),"\n",(0,o.jsx)(e.h3,{id:"basic-navigation-setup",children:"Basic Navigation Setup"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-yaml",children:'# Navigation configuration for humanoid robot\namcl:\n  ros__parameters:\n    use_sim_time: True\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_link"\n    beam_count: 60\n    do_beamskip: false\n    lambda_short: 0.1\n    likelihood_max_dist: 2.0\n    max_beams: 60\n    max_particles: 2000\n    min_particles: 500\n    odom_frame_id: "odom"\n    pf_err: 0.05\n    pf_z: 0.99\n    recovery_alpha_fast: 0.0\n    recovery_alpha_slow: 0.0\n    resample_interval: 1\n    robot_model_type: "differential"\n    save_pose_rate: 0.5\n    sigma_hit: 0.2\n    tf_broadcast: true\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.25\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.125\n    z_short: 0.05\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: True\n    global_frame: "map"\n    robot_base_frame: "base_link"\n    odom_topic: "/odom"\n    default_bt_xml_filename: "navigate_w_replanning_and_recovery.xml"\n    plugin_lib_names:\n      - "BackUp"\n      - "Spin"\n      - "Wait"\n      - "ClearEntireCostmap"\n      - "SmoothPath"\n      - "RemovePassedGoals"\n      - "TruncatePath"\n'})})]})}function m(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453(n,e,a){a.d(e,{R:()=>s,x:()=>r});var i=a(6540);const o={},t=i.createContext(o);function s(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),i.createElement(t.Provider,{value:e},n.children)}}}]);